## 常用命令

#### ssh

```ssh-keygen -t rsa -C "" -f ~/.ssh/name```

#### 开发环境linux

```linux
make start-dev-docker ssh_port_mapping=xxxx # 在启用 ssh 的情况下启动本地容器，10022 是可用端口。
make enter-dev-docker
make stop-dev-docker # 停止容器
docker container ps -a # 检查主机中现有的容器，找到你的。
docker rm container # rm后面的容器是name 或者id。
docker image ls #列出本机所有image文件
```

docker主从copy

```
# 从容器拷贝文件到主机
# 将容器：mycontainer中路径：/opt/testnew/下的文件：file.txt 拷贝到宿主机：/opt/test/路径下
docker cp mycontainer:/opt/testnew/file.txt /opt/test/

# 从宿主机拷贝文件到容器
# 将宿主机中路径：/opt/test/下的文件：file.txt拷贝到容器：mycontainer的：/opt/testnew/路径下
docker cp /home/mengda/tops_device_test.cc CONTAINER ID:/home/workspace/dtu_sdk/tests/tops
```

编译&更新

```
time make onepiece 
apt-get upd

# 更改权限
chmod 777 -R
```

#### XLA算子语义

https://www.tensorflow.org/xla/operation_semantics

#### onnx

[onnx/Operators.md at master · onnx/onnx (github.com)](https://github.com/onnx/onnx/blob/master/docs/Operators.md)

#### GIT命令

```
# 查看当前仓库分支
git remote -v  
# 从远程仓库获取最新版本到本地temp
git fetch origin master:temp  
# 合并temp到本地master分支
git merge temp
# 删除temp
git branch -d temp
# 切换分支
git checkout #分支名#
# 下载远程其他分支
git clone #分支名# #地址#
# 提交到Gerrit
git push origin HEAD:refs/for/master
# 保留当前commit
git reset HEAD^ --soft  #--hard 丢弃当前add，重新add、commit
# 推到远程不同分支
git push origin <远程分支名>
# stash后要恢复保存数据
git stash pop
```



#### bazel命令

[编译构建工具-bazel | 王竹兴 | Blob (gitee.io)](https://zhulao.gitee.io/blog/2019/04/05/编译构建工具-bazel/index.html)

```
export INTERNAL_FMK_SIM=PAVO
bazelisk run tests/hlir/cc_tests:hlir_iota_test --action_env=INTERNAL_FMK_SIM
```

#### gtest

官网：[Googletest Samples | GoogleTest](https://google.github.io/googletest/samples.html)

命令：[GTest的安装与使用 - 晓乎 - 博客园 (cnblogs.com)](https://www.cnblogs.com/helloworldcode/p/9606838.html) &&[(7条消息) gtest的介绍和使用_林海-CSDN博客_gtest](https://blog.csdn.net/linhai1028/article/details/81675724)

#### 数据类型

- U8：uint8_t  无符号整型  1bytes  0~$2^8$​​-1  (0~255)

- U16：uint16_t  2bytes  short   0~ 2^16^-1   (0~65535)

- U32：uint32_t 4bytes  int    0~2^32^-1   (0~4294967295)

- U64：max：18446744073709551615

- S8：int8_t   有符号整型  1bytes   -2^7^~2^7^-1   (-128~127)

- S16：int16_t     2bytes     -2^15^~2^15^-1   (-32768~32767)

- S32：int32_t    4bytes    -2^31^~2^31^-1     (-2147483648~2147483647)

- S64：int64_t   8bytes  -9223372036854775808 ~ 9223372036854775807 

- F16：half   2bytes  16位 1位符号位 5位指数位 10位有效数字位
  指数位 -14~15  

  最大值 2^15^(1+1023/1024) =  65504

  最小值 2^-14^(1+0/1024) = 6.103515625e-5

  ![image-20210805110437669](C:\Users\int.jialei.zhang\AppData\Roaming\Typora\typora-user-images\image-20210805110437669.png)

- F32：float  4bytes 32位   其中1位符号位 8位指数位 23位有效数字位 指数位的取值为 -126~127  有效数字位看成23位无符号整数   测试取一共8位
  则取值为 最小值：2^-126^*1 = 1.17549449095e-38 
                   最大值：2^127^*（1+2^23^-1/2^23^） = 3.40282346639e+38

- F64: double 8bytes  2.22507e-308~1.79769e+308    一共16位





```
[Feature](TR-14614) cpu_ops: add cpu sqrt ops tests
```



#### 算子功能

1. SqrtOp：开平方根
   - 
2. GeneralResizeOp：缩放图像大小
3. SoftmaxOp：
   half类型比对时由tf.softmax计算出来的half值有效数字为三位或四位，但是由cpu算子计算出来的half有效数字有六位
4. BroadcastOp：XLA
5. CholeskyOp：XLA
6. CopyOp：
7. CustomCallOp：XLA
8. OcrClsSoftmaxOp：

#### check代码

```
python3 scripts/cpp_check_offline.py
```

#### reduce语义

![image-20210826102541854](C:\Users\int.jialei.zhang\AppData\Roaming\Typora\typora-user-images\image-20210826102541854.png)



```
tf参数 ：
	input_tensor ,  
    axis = None ,  
    keep_dims = False ,  
    name = None ,  
    reduction_indices = None
    
    
struct CpuReduceParams {
    dtu::op::DataType type;
    int64_t input_shape[4];
    int64_t input_rank;
    int64_t out_shape[4];
    int64_t out_rank;
    int64_t reduce_dims[4];
    int64_t reduce_dims_rank;
    OpInformation call_back_ops[20];
    int64_t call_back_ops_num = 0;
  }
```

检查所选dim为1时的操作

hlir/ir/hlir_ops.td

reduce(Tensor& outputs, )

```c++
void reduce_new(Tensor &output, 
                const Tensor &input, 
                const Tensor &inital_value,
                std::vector<int64_t> dimensions,
                const std::string reduce_op,
                bool keepdims = false)
// reduce_op = max、min、argmax、argmin、sum、mean、prod
// dimensions 0-n个维度
```

![image-20210915105218618](C:\Users\int.jialei.zhang\AppData\Roaming\Typora\typora-user-images\image-20210915105218618.png)

reduce备注：

- int8、int16等mul容易超范围
- Ninput时先赋初值，当值max与初值相等时，下标取得还是初值的坐标





#### cholesky语义

基本思想：cholesky分解是一种将任意n阶对称正定矩阵A分解成下三角矩阵L的一种方法

![image-20210917153617823](C:\Users\int.jialei.zhang\AppData\Roaming\Typora\typora-user-images\image-20210917153617823.png)![image-20210917153638498](C:\Users\int.jialei.zhang\AppData\Roaming\Typora\typora-user-images\image-20210917153638498.png)

xla语义：参数：a（rank>2的一个浮点型数组，最高两维必须为对称正定矩阵）

​							lower（bool 使用a的下三角还是上三角）

输入数据只读a的上/下三角内容，另一半可以随便存。输出与输入shape相同，另一半三角可以是自定义或者任何数据。

当输入tensor维度大于2时，则把这个tensor视为一个批次的对称正定矩阵。

ep：input：[2, 2, 3, 3]  ----> 2*2个[3, 3]矩阵进行cholesky分解



#### codereview笔记

for循环避免使用if else

#### LayerNorm算子笔记

[pytorch LayerNorm参数的用法及计算过程_python_脚本之家 (jb51.net)](https://www.jb51.net/article/213383.htm)

